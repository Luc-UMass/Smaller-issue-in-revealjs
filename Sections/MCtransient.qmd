

## Decomposition of state space

We drop the assumption of irreducibility and develop a number of tool to study the transient behavior of Markov chains.


+ The communication relation $i \leftrightsquigarrow j$ is an [**equivalence relation**]{.red}. We use the convention  $P^0 = I$  (the identity matrix) and then also that $i \leftrightsquigarrow i$ ($i$ communicates
with itself $P^0(i,i)=1$).  
    1.  It is *reflexive* : $i \leftrightsquigarrow i$.
   
    2. It is  *symmetric*:  $i \leftrightsquigarrow j$ implies $j \leftrightsquigarrow i$.
   
    3. It is  *transitive*: $i \leftrightsquigarrow j$ and  $j \leftrightsquigarrow l$ implies $i \leftrightsquigarrow l$.

. . .

+ Using this  equivalence relation we can decompose the state space $S$ into mutually disjoint  [communication classes]{.red}
$$
S = C_1 \cup C_2 \cup \cdots \cup C_M \,.
$$

. . .

There are two kinds of communication classes, transient classes and closed classes: 

+  A class $C$  is called [**transient**]{.red} if there exists $i\in C$ and $j \in S \setminus C$ with  $i \rightsquigarrow j$. 

    This means it is possible to exit the class $C$ and never come, since it could come back it would mean $j \rightsquigarrow k$
    for $k \in C$ and thus $j \in C$. 



+  A class $C$  is called  [**closed**]{.red} classes if it is not transient that is,  for any pair  $i\in C$ and $j \in S \setminus C$ we have $i \not\rightsquigarrow j$.

    Clearly it is impossible to exit a closed class. 

. . .



## {-}


The next result state if you start in a finite transient class you will always eventually exit it (this may not be true any more $S$ is infinite).

:::{#lem-exittransient}
Suppose $S$ is finite and $X_0 \in C$ where $C$ is a transient class. 
Then $X_n$ exits $C$ after a finite time with probability $1$.  As a consequence  for $i, j \in C$ we have
$$
\lim_{n\to \infty} P^n(i,j) =0 \,.
$$
:::

. . .

:::{.proof} 

By irreducibility $X_n$ can exit $C$ starting from any $i\in C$ after a finite time. Since $C$ is finite, there exists  
$k$ and $\theta < 1$ such that 
have
$$
P \{X _k \in C | X_0=i \}  \le \theta \,\, \textrm{ for all } i \in C \,.
$$
Using the (strong) Markov property this implies  that  $P \{X _{nk} \in C | X_0=i \}  \le \theta^n$  and so 
so the probability to stay in transient class goes to $0$ as time goes by.  If $i$ and $j$ both belong to the 
transient class $C$ this can be re-expressed as 
$$
\lim_{n\to \infty} P^n(i, j) \,=\, 0 \,.
$$ 

$\quad \blacksquare$.

:::



## Communication diagram {#sec-communication}

To figure out the class structure it is convenient to build a directed graph where the vertices are the state and each 
directed edges corespond to a pair $(i,j)$ with $P(i,j)>0$.  

For example 

::::{.columns}


:::{.column width="50%"}

$$
P=
\begin{matrix}
1 \\ 2 \\ 3\\4\\5\\6\\7\\8
\end{matrix}
\begin{pmatrix}
0 & .4 & .6 & 0 & 0 & 0 & 0 &0 \\
.3 & .7 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & .5 & 0 & 0 & 0 & .5\\
0 & 0 & .2 & 0 & .8 & 0 & 0 &0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 &0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 &0 \\
0 & 0 & 0 & 0 & 0 & .3 & 0 &.7 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 &0 
\end{pmatrix}
$$

:::

:::{.column width="50%"}

![](images/communication-diagram.png)

::: 
::::

. . .

There are 4 classes: $T_1=\{1,2\}$, $T_2=\{3,4\}$, $T_3=\{5\}$ are all transient and  $C=\{6,7,8\}$ which is closed.




## Decomposition of reducible Markov chains

Markov chain with recurrent classes  $R_1, \cdots R_L$ and  transient classes denoted by  $T_1, \cdots T_K$ (set $T= T_1 \cup \cdots T_K$).  After reordering the states  the transition matrix has the block form
$$
P\,=\, 
\begin{matrix}
R_1 \\ R_2 \\ R_3 \\ \vdots \\ R_L \\ T
\end{matrix}
\begin{pmatrix}
P_1    &                     &                   &                   & &\\
            &     P_2         &                  &    0              & &\\
            &                      &  P_3       &                  &  & \\
            &       0               &                &    \ddots    &  &\\
            &                     &                 &                 &P_L &\\
            &                     &     S         &                  &      & Q
\end{pmatrix}
$${#eq-reduciblematrix}

where $P_l$ gives the transition probabilities within the class $R_l$, $Q$ the transition within the transient
classes  and $S\not= 0$ the transition from the transient classes into the recurrent classes.

It is easy to see that $P^n$ has the form
$$
P^n\,=\, 
\begin{matrix}
R_1 \\ R_2 \\ R_3 \\ \vdots \\ R_L \\ T
\end{matrix}
\begin{pmatrix}
P_1^n    &                     &                   &                   & &\\
            &     P_2^n         &                  &    0              & &\\
            &                      &  P_3^n       &                  &  & \\
            &       0               &                &    \ddots    &  &\\
            &                     &                 &                 &P_L^n &\\
            &                     &     S_n         &                  &      & Q^n
\end{pmatrix}
$$
for some matrix $S_n$.

## {-}

**Example**:
Consider the  random walk with absorbing boundary conditions (see @exm-rw1N). There are three classes, 2 closed ones  
$\{0\}$, $\{N\}$ and 1 transient $\{1, \cdots, N-1\}$ for example with $N=5$ we have 

$$
P\,=\, 
\begin{matrix}
0 \\ 5 \\ 1 \\ 2 \\ 3 \\ 4
\end{matrix}
\begin{pmatrix}
      1      &      0           &      0     &      0             &0 & 0\\
      0     &        1         &      0       &    0              & 0&   0\\
     1/2   &       0           &    0    &        1/2         & 0 & 0 \\
      0      &       0         &      1/2      &    0    & 1/2 &   0   \\
     0       &      0          &        0       &      1/2        &   0 & 1/2\\
      0      &      1/2         &     0        &       0         & 1/2     & 0
\end{pmatrix}
$$
To get a feel of what's going on we find (rounded to 4 digit precision)

$$
P^{20} = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 \\
0.7942 & 0.1953 & 0.004 & 0 & 0.0065 & 0 \\
0.5924 & 0.3907 & 0 & 0.0104 & 0 & 0.0065 \\
0.3907 & 0.5924 & 0.0065 & 0 & 0.0104 & 0 \\
0.1953 & 0.7942 & 0 & 0.0065 & 0 & 0.004 \\
\end{pmatrix}\,, \quad
P^{50}=\begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 \\
0.8 & 0.2 & 0 & 0 & 0 & 0 \\
0.6 & 0.4 & 0 & 0 & 0 & 0 \\
0.4 & 0.6 & 0 & 0 & 0 & 0 \\
0.2 & 0.8 & 0 & 0 & 0 & 0 \\
\end{pmatrix}
$$

As expected starting in transient class the Markoveventually exit it to reach here of one the two recurrent class. From $P^50$ one can read that starting in, say state $2$ with probability $.6$ the Markov chain will end up at $0$ and with  probability $.4$ the Markov chain will end up in $5$.  We will learn how to compute these probability later on but we study first how long it takes to exit the closed class. 

## Absorption time   

+ Starting in a recurrent class $R_l$ the Markov chain stays in $R_l$ forever and its behavior is dictated entirely by the irreducible matrix $P_l$ with state space $R_l$. 

+ Starting from a transient class the Markov chain will eventually exit the class $T$ and is absorbed into some recurrent class. One basic question is: **What is the expected time until absorption**?   

+ We define the [**absorption time**]{.red}
$$
\tau_{\textrm{abs}} = \min\{ n \ge 0 \,;\,  X_n \notin T \}
$$


:::{#thm-absorptiontime name="Expected time until absorption"} 
Let $j$ be a transient state and let $\tau_{\textrm{abs}}$ to be the time until the Markov chain reaches some closed class. Then we have
$$
E[\tau_{abs} |X_0=j] \,=\, \sum_{i\in T} M(j,i) \,.
$$
where 
$$
M=(I-Q)^{-1} =  1 + Q + Q^2 + \cdots
$$
and $Q$ is from the decomposition @eq-reduciblematrix.
:::



## {-}

:::{.proof} 
From @lem-exittransient we know that $Q^n(i,j) \to 0$ and so all eigenvalues of $Q$  have absolute
values strictly less than $1$.  Therefore $I-Q$ is an invertible matrix and we can define
$$
M = (I-Q)^{-1} = I +Q +Q^2 + Q^3 + \cdots
$$
The second equality is the geometric series for matrices which follows from the identity 
$$
(I+ Q + \cdots Q^n)(1-Q) = I -Q^{n+1} \,.
$$
To give  a probabilistic interpretation to the matrix $M$ we introduce the random variable  
$$
Y(i) \,=\, \sum_{n=0}^\infty 1_{\{X_n=i\}} \quad  = \textrm{ total number of visits to state } i
$$
If $i$ is transient by @lem-exittransient $Y(i) < \infty$  with probability $1$.  If $j$ is another transient state we have 
$$
E[ Y(i) \,\vert\, X_0=j]= \,E\left[  \sum_{n=0}^\infty {\bf 1}_{\{X_n=i\}} \,\vert\, X_0=j\right]  
\,=\,\sum_{n=0}^\infty P\left\{ X_n=i \,\vert\, X_0=j\right\}  
\,=\,\sum_{n=0}^\infty Q^n(i,j) = M(i,j)
$$
That is  $M(j,i)$ is simply the expected number of visits to $i$ if $X_0=j$ and thus, summing over all the transient states we obtain 
$$
E[\tau_{abs} |X_0=j] \,=\, \sum_{i\in T} M(j,i) \,.  \quad \blacksquare
$$




::: 



## Hitting time in irreducible Markov chain 

+ Suppose $X_n$ is irreducible and we are interested in computing the expected time to reach one state from another state that 
is  $E[ \tau(i)| X_0=j] \textrm{ for } j \not= i$. 

+ If $i=j$ then from @thm-ergMC that $E[ \tau(i)| X_0=i]=\pi(i)^{-1}$ where $\pi$ is the stationary distribution. 

+  If $i \not= j$  we use the following idea. Relabel the states such the first state is $i$ and modify $P$ such that $i$ is an absorbing state  
$$
P = 
\begin{pmatrix}
 P(i,i)  & R \\  S & Q
\end{pmatrix}
\quad \quad \longrightarrow \quad \quad
\widetilde{P} = 
\begin{pmatrix}
 1  & 0 \\  S & Q
\end{pmatrix}
$${#eq-dec}

The fact that $P$ is irreducible implies that $S\setminus \{i\}$ is a transient class for the modified transition matrix $\widetilde{P}$. 
The return time $\tau(i)$ starting from $i\not= j$ for the Markov chain with transition $P$ is  exactly the same as the absorption time for the Markov chain with transtion $\widetilde{P}$. Indeed the hitting time does not depend on the submatrix $R$.  Therefore from 
@thm-absorptiontime we obtain immediately 

:::{#thm-hittingtime name="Expected hitting time in irreducible Markov chain"}
Let $X_n$ be an irreducible Markov chain. For $i \not= j$ we
$$
E[\tau^(i) |X_0=j] \,=\, \sum_{l\in T} M(j,l) \,.
$$
where $M=(I-Q)^{-1}$ and $Q$ is given in @eq-dec and is obtained by deleting the $i^{th}$ row and $i^{th}$ column from $P$.

:::



## Examples


**Example**(continued): Random walk with absorbing boundary conditions on $\{0,1,\cdots,5\}$. We get   
$$
Q\,=\, \begin{pmatrix}
       0    &        1/2         & 0 & 0 \\
           1/2      &    0    & 1/2 &   0   \\
       0       &      1/2        &   0 & 1/2\\
     0        &       0         & 1/2     & 0
\end{pmatrix} \quad \implies 
\quad  
M=(I-Q)^{-1}
\,=\, 
\begin{pmatrix}
       1.6    &        1.2         & 0.8 & 0.4 \\
        1.2      &    2.4    & 1.6 &   0.8  \\
       0.8      &      1.6        &   2.4 & 1.2\\
     0.4        &       .8         & 1.2     & 1.6
\end{pmatrix}
$$
and thus the expected times until absorption are $4$ for states $1$ and $4$ and $6$ for states $2$ and $3$.

**Example**: Random walk with reflecting boundary conditions (see @exm-rw1N) with $N=5$ and we compute $E[ \tau(0) | X_0=i]$. The stationary distribution is $\pi = \left(\frac{1}{10}, \frac{2}{10}, \frac{2}{10}, \frac{2}{10}, \frac{2}{10}, \frac{1}{10}\right)$ so $E[ \tau(0) | X_0=0]=10$.  For $i\not=0$ we delete the first row and column from $P$ and have 
$$
Q\,=\, \left( \begin{array}{ccccc}
    0     &    1/2  & 0    & 0     &0 \\
  1/2    &    0    & 1/2  &   0   &0 \\
    0     &   1/2  &   0   & 1/2  &0 \\
    0     &     0    & 1/2  & 0    &1/2  \\
     0     &     0    & 0     & 1  &0
\end{array}
\right)  \,,
\quad
M=(I-Q)^{-1}
\,=\, \left( \begin{array}{ccccc}
       2    &     2    &  2 & 2 & 1\\
        2    &    4    &  4 &   4    &2 \\
       2     &     4    &  6 & 6& 3\\
     2       &     4     & 6  & 8 & 4 \\
     2       &      4    & 6  & 8 & 5
\end{array} \right)
$$
and so the expected return times to $1$ are  $10,  9, 16, 21, 24, 25$ respectively. 



## Absorption probabilities

+ If $X_0 = i \in T$ belongs to some transient class and if there are more than one closed classes, say  $R_1, R_2, \cdots, R_L$ then the Markov may be absorbed in distinct closed class and so we wisht to compute the probabilities 
$$
 P\{  X_n \,\,\textrm{ reaches class } R_l  \,|\, X_0=i \}  
$$

+ Without loss of generality  we can assume that each closed class is an absorbing state $r_1,  \cdots r_L$ (we can always collapse a closed class into a absorbing state since it does not matter which state in the recurrent class we first visit).  We denote the transient states by  $t_1, \cdots, t_M$ and upon reordering the state the transition matrix has the form 
$$
P\,=\, 
\begin{matrix}
r_1 \\ \vdots \\ r_l \\ t_1  \\ \vdots \\ t_M  
\end{matrix}
\begin{pmatrix}
    &   &  &  &  &  \\
     & I &  & &0& \\
     &   &  & &  &  \\
   &   &   &  &  &  \\
   & S &  &  &Q & \\
    &   &  & &  & \\
\end{pmatrix}
$${#eq-transitionabsorption}



+  We wish to compute 
$$
A( t_i, r_l) = P\{  X_n  \, \textrm{ reaches } r_l   \,|\, X_0= t_i\}\,.
$$
and it will be convenient to set  $A(r_l, r_l)=1$ and $A(r_k, r_k)=0$ if $k\not= l$.

## {-} 

:::{#thm-absorptionprobabilities name="Absorption probabilities in closed classes"}
For a Markov chain with transition matrix @eq-transitionabsorption where the states $t_1, \cdots t_M$ are transient we have
$$
P\{  X_n  \, \textrm{ reaches } r_l   \,|\, X_0= t_i\}  = A(t_i, r_l) \quad \textrm{ with } \quad   A = (I -Q)^{-1} S
$$
:::

:::{.proof}  

We condition on the first step of the Markov chain to obtain
$$
\begin{aligned}
A( t_i, r_l) &= P \left\{ X_n = r_l {\rm ~eventually~} \vert X_0= t_i\right\}  \\
             &= \sum_{k \in S} P \left\{ X_n = r_l \textrm{ eventually}, X_1=k \vert X_0= t_i\right\} \\
            &= \sum_{ k \in S} P \left\{ X_1 = k \vert  X_0= t_i\right\} P \left\{ X_n = r_j
                           {\rm ~eventually~} \vert X_1= k\right\}  \\
            &=   \sum_{ k \in S} P(t_i, k) A( k, r_j) \,=\,  P(t_i, r_l) +   \sum_{ t_k } P(t_i, t_k) A( t_k, r_j)  \,.  
\end{aligned}
$$
If $A$ be the $L \times M$ matrix with entries $A(t_i, r_l)$, then this can  be written in matrix form
as
$$
A \,=\,  S + Q A
$$
or
$$
A \,=\, (I-Q)^{-1} S \,=\, MS \,.
$$

::: 

## {-}

Continuing with the Random walk with absorbing boundary conditions, we get 
$$
A \,=\, MS \,=\,
\left( \begin{array}{cccc}
       1.6    &        1.2         & 0.8 & 0.4 \\
        1.2      &    2.4    & 1.6 &   0.8  \\
       0.8      &      1.6        &   2.4 & 1.2\\
     0.4        &       .8         & 1.2     & 1.6
\end{array} \right)
 \left( \begin{array}{cc} 1/2 & 0 \\   0 & 0 \\ 0 & 0 \\  0 & 1/2 \end{array}\right)
\,=\,
\left( \begin{array}{cc} .8 & .2 \\   .6 & .4 \\ .4 & .6 \\  .2 & .8 \end{array}\right)
$$
 For example from state $2$ the probability to be absorbed in $0$ is $.6$, and so on....



## Tennis game

+ We model tennis as a Markov chain: For each point  player $A$ will win with probability $p$  and player $B$ will be win with probability $q=1-p$ and we assume all points are independent. Winning a game leads to the Markov chain with following communication diagram. 

:::{.columns}

:::{.column width=50%}
![Tennis communication diagram](images/Tennis.png)
:::

:::{.column width=50%}

+ The Markov chain "moves up" until it reaches one of the 5 states on the top (which we relabel $0,1,2,3,4$) and the chains stays on those 5 states forever and performs a random walks with absorbing boundary conditions. 

+ Want the probability that $A$ wins, of course starting from the initial conditions $0-0$.  Compute this probability by successive conditioning. 

+ Consider the events 
  $$
  D_i=\{ X_n \textrm{ reaches the top row in state } i \}
  $$

+ We compute $P(D_i)$ simply by enumerating all the paths leading up to state $i$ starting form the initial state.  

:::

:::

## {-} 

+ We find 

$$
P(D_0)=p^4 + 4 qp^4\,, \quad 
P(D_1)=4p^3q^2\,, \quad 
P(D_2)= 6p^2q^2\,, \quad 
P(D_3)= 4p^2q^3\,, \quad 
P(D_4)=q^4 + 4 pq^4 \quad 
$$

+ Conditioning on the $B_i$'s:  $\displaystyle P(A) =\sum_{i=0}^4 P(A|D_i) P(D_i)$

+ Obviously we have $P(A|D_0) =1$ and $P(A|D_4) =0$. By conditioning on the first step we find
the system of equations
$$
\begin{aligned}
P(A|D_1) &= p + q P(A|B_2)                &           & P(A|D_1)  = \frac{p (1-pq)}{1-2pq}   \\
P(A |D_2) &= pP(A |D_1) + q P(A |D_3) & \implies \quad\quad  & P(A|D_2) = \frac{p^2}{1-2pq}\\
P(A |D_3) &= p P(A|D_2)                   &           & P(A|D_3)  = \frac{p^3}{1-2pq}
\end{aligned}
$$
 + Putting everyting together

:::{.columns}

:::{.column width=50%}
$$
P(A) = \frac{p^4 (1+2q)(1+4q^2)}{1-2pq}
$$
:::

:::{.column width=50%}

![](images/tennis-probabilities){width=50%}

:::

:::



## Gambler's ruin

+ A gambler is coming to the casino to play the game of dice called [craps](https://en.wikipedia.org/wiki/Craps). At this game the standard bet (pass line bet) has even money odds and the probability to win is $\frac{244}{495}=0.49292929...$, one of the casino games with best odds. 


+ Suppose that the player start with a fortune of $j$ and bets $1$ in every game.  Their ultimate goal is to reach a fortune of $N$ and, if they do, they would stop. Of course they could lose all their money before reaching they goal.        

+ The game is described by a random walk on $\{0,1, \cdots, N\}$ with absorbing boundary conditions and we want to compute
$$
\alpha_j = P(X_n \textrm{ reaches } N \textrm{ before reaching } 0| X_0=j)
$$

+ Conditioning on the first step gives the second order homogeneous linear difference equation
$$
\alpha_j = p \alpha_{j+1} + (1-p) \alpha_{j-1} \quad \textrm{ with boundary conditions } \alpha_0=0\,, \alpha_N=1 
$$


+ To solve this second order homogeneous linear difference equations we look for solutions of the form $\alpha_j=x^j$ which leads to the equation 
$$
px^2 - x + (1-p) =0  \quad \implies x_1=1\,, x_2= \frac{1-p}{p} 
$${#eq-qegr}
This leads to the system of equation (for $p\not= \frac12$)
$$
\alpha_j= C_1 + C_2 \left(\frac{1-p}{p} \right)^j \quad \textrm{ with } \quad  \left\{ \begin{array}{r} C_1+C_2=0 \\ C_1 + C_2\left(\frac{1-p}{p} \right)^N=1 \end{array} \right.
$$

## {-}

+ Solving gives the **Gambler's ruin probabilities**  
$$
\alpha_j = \frac{ 1 - \left( \frac{1-p}{p} \right)^j }{1 -\left( \frac{1-p}{p} \right)^N}  \quad \quad \textrm{ Gambler's ruin for } q\not= p
$$

+ If $p=\frac{1}{2}$ the quadratic equation @eq-qegr has a double root $1$ but we note that $\alpha_j= j$ is a second linearly independent solution of $\frac{1}{2}\alpha_{j+1} - \alpha_j + \frac{1}{2}\alpha_{j-1}=0$.  Solving the equation $\alpha_j= C_1 + C_2j$ with the boundary conditions gives 
$$
\alpha(j) \,=\, \frac{j}{N}   \quad \quad \textrm{ Gambler's ruin for } p=\frac{1}{2}
$$


+ **How bad does it get?**:For example if $p=\frac{244}{495}$ and you start with a fortune a 50 and want to double it, the probability to succeed is 
$\frac{ 1 - \left( \frac{251}{244}\right)^{50}}{1 -\left(\frac{251}{244}\right)^{100}}=.1955$, not so great. You could also be more risky
and bet an amount of 10 in which case you probability to succeed i a much better $\frac{ 1 - \left( \frac{251}{244}\right)^{5}}{1 -\left(\frac{251}{244}\right)^{10}}=.4647$. Even better bet everything and your probability to win is $p=.4929$. (In casino boldness pays, or loses less).


## {-} 

+ **Limiting cases**   To get a better handle on the gambler's ruin formula we slightly rephrase the problem:

    + We start at $0$.

    + We stop whenever we reach $W$ ($W$ is the desired gain) 0r when we reach $-L$ ($L$ is the acceptable losss).

    + The state are now $j \in \left\{ -L, -L+1, \cdots, \cdots, W-1, W\right\}$ 
    
  We get 
  $$
  P(-L, W)\,\equiv\, P\left( {\rm Reach~}W{\rm~before~reaching~} - L {\rm ~starting~from~}0 \right) \,=\, \frac{1 - \left( \frac{1-p}{p} \right)^L}{1 -     \left( \frac{1-p}{p} \right)^{L+W}} \,.
  $$


+ The limit $L \to \infty$ describes a  player with infinite wealth:  
  $$
  P(-\infty,L)= \left\{\begin{array}{cl}1 & {\rm~if~} p> \frac12 \\ \left(\frac{p}{1-p}\right)^W & {\rm~if~} p<  \frac12 \end{array} \right.
 $$
  Even with infinite wealth it is exponentially hard to win $W$! 
  
+ The limit $W \to \infty$ describes a player with fortune $L$ who does not stops unless they lose.
$$
P(-L,\infty) \,=\, \left\{\begin{array}{cl} 1 - \left(\frac{1-p}{p}\right)^L & {\rm~if~} p > \frac{1}{2}
\\ 0 & {\rm~if~} p < \frac{1}{2} \end{array} \right.
$$
The probability to play forever is, unsurprisingly, $0$.  



